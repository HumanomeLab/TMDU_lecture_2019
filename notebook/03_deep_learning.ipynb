{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_introduction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6_yQe3GplVB-"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAUu64DRSfry",
        "colab_type": "text"
      },
      "source": [
        "# 0. 準備\n",
        "\n",
        "## 0.1. スライドとデータ\n",
        "* データ （前回同様）CSV形式：[exp_data.csv](https://github.com/HumanomeLab/TMDU_lecture_2019/blob/master/data/exp_data.csv)\n",
        "\n",
        "## 0.2 GPUの有効化\n",
        "\n",
        "以下の手順でGPUを選択する。\n",
        "* 英語：Edit > Notebook Settings > Hardware Accelerator \n",
        "* 日本語：編集 > ノートブックの設定 > ハードウェアアクセレレータ\n",
        "\n",
        "今回は、ほとんど効果が無いですが・・・\n",
        "\n",
        "## 0.3 データのアップロード\n",
        "\n",
        "前回同様、データをアップロードする。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl6H5ueyL7zj",
        "colab_type": "text"
      },
      "source": [
        "# 1. NNを用いたクラス分類2 (PyTorch)\n",
        "\n",
        "PyTorchで深層学習を実装をしていく。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvCZqbcRwQKm",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 前準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdxXp_Vvv2ZT",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.1 パッケージとデータの準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E1UI21GMeT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PyTorch で用いられるクラス群\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import transforms\n",
        "import torch.utils.data as data\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import os\n",
        "import copy\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_6JWjzKoDX7",
        "colab_type": "text"
      },
      "source": [
        "exp_data.csvに対して、以下のことを実施する make_dataset 関数を作成する。\n",
        "1. データの読み込み\n",
        "2. クラスを以下のベクトル形式で指定する　（one-hot vector と呼ばれる）\n",
        "  * クラスが0 (y==0) なら、\\[1, 0\\]\n",
        "  * クラスが1 (y==1) なら、\\[0, 1\\]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpvvZVPpO1Q-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データ読み込み関数を作成する。\n",
        "def make_dataset():\n",
        "    labels = []\n",
        "    # データの読み込みと特徴量の選択\n",
        "    dataset = pd.read_csv(\"exp_data.csv\", index_col=\"Name\")\n",
        "    df = dataset.drop(\"class\", axis=1)\n",
        "    # df の値を取り出し、型を変換する\n",
        "    X = df.values.astype(np.float32)\n",
        "    y = np.array(dataset[\"class\"].values)\n",
        "    # クラスの値を one-hot-vector に変換する\n",
        "    for y_i in y:\n",
        "        c = [0, 0]  # one-hot-vector\n",
        "        if y_i == 0.0:\n",
        "            c = [1, 0]\n",
        "        else:\n",
        "            c = [0, 1]\n",
        "        labels.append(np.array(c))\n",
        "    return X, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ0Xb88sPWwP",
        "colab_type": "text"
      },
      "source": [
        "データの読み込み。訓練データ、テストデータに加えて、バリデーションデータも作成する。深層学習では、正しく学習が進んでいるかどうかの判断に、バリデーションデータを利用する。\n",
        "訓練データ、テストデータ、バリデーションデータの分割は、いずれも train_test_split を利用する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wbzwoiCPOFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 全データの読み込み\n",
        "X, y = make_dataset()\n",
        "# テストデータの分割\n",
        "X_tmp, X_test, y_tmp, y_test = train_test_split(X, y, test_size = 0.20)\n",
        "# 訓練データとValidationデータの分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_tmp, y_tmp, test_size = 0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rSm_yiu-ISp",
        "colab_type": "text"
      },
      "source": [
        "正しく分割できているか確認するため、サンプル数を表示してみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsSOmv07-kAF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5dce6c5d-3936-4ab7-b050-25d142be3b10"
      },
      "source": [
        "print(\"X:\", X.shape)\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"X_val:\", X_val.shape)\n",
        "print(\"X_test:\", X_test.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X: (994, 906)\n",
            "X_train: (596, 906)\n",
            "X_val: (199, 906)\n",
            "X_test: (199, 906)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wztuXSD7qey0",
        "colab_type": "text"
      },
      "source": [
        "DatasetFolderクラスを定義する。各サンプル点の変数をsampleに、クラスをtargetsに保持する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCApc9r9Pm5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データを入れておくための倉庫\n",
        "class DatasetFolder(data.Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.samples = X\n",
        "        self.targets = y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # index番目の変数とクラスを返す\n",
        "        sample = self.samples[index]\n",
        "        target = self.targets[index]\n",
        "        sample = torch.from_numpy(sample)  # numpyからPyTorchの型へ変換\n",
        "        target = torch.from_numpy(target)  # numpyからPyTorchの型へ変換\n",
        "        return sample, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "# 訓練データ, バリデーションデータ, テストデータをそれぞれ, \n",
        "# 'train', 'val', 'test' に保持する辞書を作成\n",
        "# 例えば、 feature_datasets['train'] で訓練データのリストが得られる\n",
        "feature_datasets = {\n",
        "    'train':DatasetFolder(X_train, y_train),\n",
        "    'val':DatasetFolder(X_val, y_val),\n",
        "    'test': DatasetFolder(X_test, y_test)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wbh4PUQT3y_Y",
        "colab_type": "text"
      },
      "source": [
        "訓練データ、バリデーションデータ、テストデータのデータの読み込み方（バッチサイズ、シャッフルの有無など）を指定する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyJ5ii96QYgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# バッチサイズ分のデータを読み込むための準備。\n",
        "# 訓練データ（train）はshuffle=Trueを指定することで、\n",
        "# データの順番をシャッフルし、読み込む順番をランダムにする。\n",
        "# 他はシャッフルの必要なし。\n",
        "batch_size=32\n",
        "workers=0\n",
        "dataloaders = {\n",
        "    # 訓練データ\n",
        "    'train': torch.utils.data.DataLoader(\n",
        "        feature_datasets['train'],\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=workers),\n",
        "    # バリデーションデータ\n",
        "    'val': torch.utils.data.DataLoader(\n",
        "        feature_datasets['val'],\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=workers),\n",
        "    # テストデータ\n",
        "    'test': torch.utils.data.DataLoader(\n",
        "        feature_datasets['test'],\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=workers)\n",
        "}\n",
        "\n",
        "# 訓練, バリデーション, テストデータのサンプル数を数える\n",
        "dataset_sizes = {x: len(feature_datasets[x]) for x in ['train', 'val', 'test']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTV8s7BQ3pXe",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.2 ネットワークの定義\n",
        "\n",
        "入力層のノード数が906 (全遺伝子分)、中間層のノード数が64のネットワークを作成する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSHNmk2bQnir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(906, 64)\n",
        "        self.fc2 = nn.Linear(64, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# ここから先は、作成したネットワークを、指定のデバイスに送るための内容。\n",
        "# 今回はGPUが利用できる（ように設定している）ので、torch.cuda.is_available() が\n",
        "# true となり、cuda （GPU）にデータが送られて計算される。\n",
        "# CPUしか無い場合には、CPU上で計算。\n",
        "device_name = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    device_name = \"cuda\"\n",
        "device = torch.device(device_name)\n",
        "model = Net()\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWuSW69NQ0jL",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.3 作成したネットワークの確認\n",
        "\n",
        "自身が作成したネットワークが意図しているものと同じかどうかを確かめるため、表示する。PyTorchでは、torchsummary を用いるとモデルの概要を出力できる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13KbFnhXQywW",
        "colab_type": "code",
        "outputId": "b3503bc6-a6f8-4c1c-f4df-7ddbca787bc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (1,906))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                [-1, 1, 64]          58,048\n",
            "            Linear-2                 [-1, 1, 2]             130\n",
            "================================================================\n",
            "Total params: 58,178\n",
            "Trainable params: 58,178\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.22\n",
            "Estimated Total Size (MB): 0.23\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4M21go6Tzs1",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.4 モデルを訓練する関数の定義\n",
        "モデルを訓練する train_model を定義する。\n",
        "この関数は、大きく２つのfor文でできている。\n",
        "\n",
        "\"for epoch in range()\"の中は、1エポックの実行である（12〜60行目）。各ループの最後に、更新したモデルがバリデーションデータの上で精度が良くなっているか確認し（55行目）、よくなっていればモデルを保存する（56、57行目）。\n",
        "\n",
        "\"for inputs, labels in dataloaders...\"の中は１つのバッチの実行である（26〜46行目）。今のモデルを利用したときの目的関数（スライドのL）の値の計算（38行目）、勾配降下法を実施（41, 42行目）を行う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m1k7QHTRC4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "    # 途中経過でモデル保存するための初期化\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 10000.0\n",
        "    # 時間計測用\n",
        "    end = time.time()\n",
        "    \n",
        "    # ネットワークの表示\n",
        "    print(model)\n",
        "    print()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch:{}/{}'.format(epoch, num_epochs - 1), end=\"\")\n",
        "\n",
        "        # 各エポックで訓練+バリデーションを実行\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train(True)  # training mode\n",
        "            else:\n",
        "                model.train(False)  # evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                labels = labels.float()\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 訓練のときだけ履歴を保持する\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, classnums = torch.max(labels, 1)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, classnums)\n",
        "                    # 訓練時にはバックプロパゲーションを実施\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # 統計情報\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == classnums)\n",
        "                \n",
        "            # サンプル数で割って平均を求める\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('\\t{} Loss: {:.4f} Acc: {:.4f} Time: {:.4f}'.format(phase, epoch_loss, epoch_acc, time.time()-end), end=\"\")\n",
        "            \n",
        "            # 学習が進むに連れ、更新量を減らすための処理\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "            # 精度が改善したらモデルを保存する\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            end = time.time()\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print()\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val acc: {:.4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP7u6gtAUtBA",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.5 テストデータにおける評価のための関数\n",
        "\n",
        "学習したモデルについてテストデータにおける精度を調査するための関数を定義する。ほとんど訓練時と同じ関数だが、バックプロパゲーションが無いなど、簡素化されている。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ5DlueLT4fm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# テストデータの評価\n",
        "def print_test_accuracy(model, criterion, phase):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    model.train(False)\n",
        "\n",
        "    for inputs, labels in dataloaders[phase]:\n",
        "        labels = labels.float()\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # 訓練のときだけ履歴を保持する\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "            outputs = model(inputs)\n",
        "            _, classnums = torch.max(labels, 1)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, classnums)\n",
        "        # 統計情報\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == classnums)\n",
        "\n",
        "    # サンプル数で割って平均を求める\n",
        "    epoch_loss = running_loss / dataset_sizes[phase]\n",
        "    epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "    print('On Test:\\tLoss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgDY4E2VU4UP",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 モデルの学習と評価"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "segaKXuW9oMw",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.1 モデルの学習\n",
        "目的関数を交差エントロピーで、確率的勾配降下法でパラメータを更新し、モデルを学習する。また、テストデータを用いて予測精度を計算する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwkdiXPDUzTo",
        "colab_type": "code",
        "outputId": "61c94516-36a3-4c16-8658-59c82b59367f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "source": [
        "epochs = 40\n",
        "batch_size = 32\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "outdir = \".\"\n",
        "\n",
        "# 目的関数（クロスエントロピー）、\n",
        "# パラメータの最適化方法、学習率の更新方法を定義。\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)\n",
        "\n",
        "# 実際の学習を実施\n",
        "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=epochs)\n",
        "# テストデータでの精度を求める\n",
        "print_test_accuracy(model, criterion,  'test')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=906, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "\n",
            "Epoch:0/39\ttrain Loss: 0.6483 Acc: 0.8557 Time: 0.0410\tval Loss: 0.6316 Acc: 0.7337 Time: 0.0077\n",
            "Epoch:1/39\ttrain Loss: 0.6146 Acc: 0.8121 Time: 0.0393\tval Loss: 0.5952 Acc: 0.5879 Time: 0.0066\n",
            "Epoch:2/39\ttrain Loss: 0.5666 Acc: 0.8003 Time: 0.0310\tval Loss: 0.5351 Acc: 0.9397 Time: 0.0064\n",
            "Epoch:3/39\ttrain Loss: 0.5235 Acc: 0.8440 Time: 0.0299\tval Loss: 0.4805 Acc: 0.8442 Time: 0.0058\n",
            "Epoch:4/39\ttrain Loss: 0.4939 Acc: 0.8473 Time: 0.0350\tval Loss: 0.4650 Acc: 0.9497 Time: 0.0065\n",
            "Epoch:5/39\ttrain Loss: 0.4455 Acc: 0.9010 Time: 0.0310\tval Loss: 0.4300 Acc: 0.9548 Time: 0.0064\n",
            "Epoch:6/39\ttrain Loss: 0.4338 Acc: 0.8893 Time: 0.0320\tval Loss: 0.4094 Acc: 0.7889 Time: 0.0062\n",
            "Epoch:7/39\ttrain Loss: 0.4335 Acc: 0.8859 Time: 0.0311\tval Loss: 0.4266 Acc: 0.9397 Time: 0.0063\n",
            "Epoch:8/39\ttrain Loss: 0.4008 Acc: 0.8993 Time: 0.0307\tval Loss: 0.3472 Acc: 0.9347 Time: 0.0064\n",
            "Epoch:9/39\ttrain Loss: 0.3612 Acc: 0.9312 Time: 0.0312\tval Loss: 0.3256 Acc: 0.9648 Time: 0.0064\n",
            "Epoch:10/39\ttrain Loss: 0.3443 Acc: 0.9362 Time: 0.0360\tval Loss: 0.3162 Acc: 0.9598 Time: 0.0060\n",
            "Epoch:11/39\ttrain Loss: 0.3312 Acc: 0.9430 Time: 0.0320\tval Loss: 0.3509 Acc: 0.8492 Time: 0.0062\n",
            "Epoch:12/39\ttrain Loss: 0.3276 Acc: 0.9396 Time: 0.0318\tval Loss: 0.2991 Acc: 0.9648 Time: 0.0062\n",
            "Epoch:13/39\ttrain Loss: 0.3340 Acc: 0.9262 Time: 0.0314\tval Loss: 0.3680 Acc: 0.9447 Time: 0.0061\n",
            "Epoch:14/39\ttrain Loss: 0.3675 Acc: 0.9010 Time: 0.0322\tval Loss: 0.2843 Acc: 0.9648 Time: 0.0064\n",
            "Epoch:15/39\ttrain Loss: 0.3039 Acc: 0.9430 Time: 0.0325\tval Loss: 0.2946 Acc: 0.9497 Time: 0.0061\n",
            "Epoch:16/39\ttrain Loss: 0.2951 Acc: 0.9413 Time: 0.0351\tval Loss: 0.2789 Acc: 0.9497 Time: 0.0061\n",
            "Epoch:17/39\ttrain Loss: 0.2917 Acc: 0.9480 Time: 0.0320\tval Loss: 0.2626 Acc: 0.9598 Time: 0.0063\n",
            "Epoch:18/39\ttrain Loss: 0.2839 Acc: 0.9547 Time: 0.0320\tval Loss: 0.2570 Acc: 0.9548 Time: 0.0061\n",
            "Epoch:19/39\ttrain Loss: 0.2837 Acc: 0.9547 Time: 0.0314\tval Loss: 0.2731 Acc: 0.9497 Time: 0.0063\n",
            "Epoch:20/39\ttrain Loss: 0.2747 Acc: 0.9497 Time: 0.0316\tval Loss: 0.2715 Acc: 0.9497 Time: 0.0061\n",
            "Epoch:21/39\ttrain Loss: 0.2682 Acc: 0.9530 Time: 0.0354\tval Loss: 0.2577 Acc: 0.9648 Time: 0.0065\n",
            "Epoch:22/39\ttrain Loss: 0.2699 Acc: 0.9497 Time: 0.0327\tval Loss: 0.2417 Acc: 0.9598 Time: 0.0065\n",
            "Epoch:23/39\ttrain Loss: 0.2611 Acc: 0.9497 Time: 0.0328\tval Loss: 0.2391 Acc: 0.9497 Time: 0.0062\n",
            "Epoch:24/39\ttrain Loss: 0.2621 Acc: 0.9497 Time: 0.0310\tval Loss: 0.2354 Acc: 0.9497 Time: 0.0060\n",
            "Epoch:25/39\ttrain Loss: 0.2575 Acc: 0.9547 Time: 0.0310\tval Loss: 0.2507 Acc: 0.9598 Time: 0.0060\n",
            "Epoch:26/39\ttrain Loss: 0.2545 Acc: 0.9547 Time: 0.0308\tval Loss: 0.2590 Acc: 0.9598 Time: 0.0060\n",
            "Epoch:27/39\ttrain Loss: 0.2594 Acc: 0.9547 Time: 0.0421\tval Loss: 0.2579 Acc: 0.9397 Time: 0.0060\n",
            "Epoch:28/39\ttrain Loss: 0.2517 Acc: 0.9463 Time: 0.0299\tval Loss: 0.2280 Acc: 0.9648 Time: 0.0060\n",
            "Epoch:29/39\ttrain Loss: 0.2556 Acc: 0.9530 Time: 0.0308\tval Loss: 0.2417 Acc: 0.9598 Time: 0.0061\n",
            "Epoch:30/39\ttrain Loss: 0.2421 Acc: 0.9497 Time: 0.0310\tval Loss: 0.2244 Acc: 0.9648 Time: 0.0060\n",
            "Epoch:31/39\ttrain Loss: 0.2400 Acc: 0.9564 Time: 0.0313\tval Loss: 0.2323 Acc: 0.9648 Time: 0.0060\n",
            "Epoch:32/39\ttrain Loss: 0.2370 Acc: 0.9497 Time: 0.0313\tval Loss: 0.2175 Acc: 0.9548 Time: 0.0060\n",
            "Epoch:33/39\ttrain Loss: 0.2362 Acc: 0.9547 Time: 0.0349\tval Loss: 0.2163 Acc: 0.9548 Time: 0.0077\n",
            "Epoch:34/39\ttrain Loss: 0.2339 Acc: 0.9530 Time: 0.0317\tval Loss: 0.2342 Acc: 0.9598 Time: 0.0062\n",
            "Epoch:35/39\ttrain Loss: 0.2331 Acc: 0.9530 Time: 0.0330\tval Loss: 0.2154 Acc: 0.9598 Time: 0.0072\n",
            "Epoch:36/39\ttrain Loss: 0.2346 Acc: 0.9513 Time: 0.0311\tval Loss: 0.2139 Acc: 0.9598 Time: 0.0060\n",
            "Epoch:37/39\ttrain Loss: 0.2332 Acc: 0.9530 Time: 0.0317\tval Loss: 0.2121 Acc: 0.9598 Time: 0.0059\n",
            "Epoch:38/39\ttrain Loss: 0.2308 Acc: 0.9513 Time: 0.0312\tval Loss: 0.2088 Acc: 0.9497 Time: 0.0061\n",
            "Epoch:39/39\ttrain Loss: 0.2250 Acc: 0.9530 Time: 0.0331\tval Loss: 0.2078 Acc: 0.9497 Time: 0.0063\n",
            "\n",
            "Training complete in 0m 2s\n",
            "Best val acc: 0.9648\n",
            "On Test:\tLoss: 0.3402 Acc: 0.9196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_yQe3GplVB-",
        "colab_type": "text"
      },
      "source": [
        "## 1.3 モデルの変更 (Dropoutを追加する)\n",
        "\n",
        "過学習傾向にある可能性があるので、過学習を避けるために、Dropoutを実施する。中間層でDropoutを実施する。\n",
        "Dropout とは、ランダムにネットワークを間引いて学習することで、過学習を避ける際に利用される方法の一つ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQlyIkTGjkbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ネットワークの定義\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(906, 64)\n",
        "        self.fc2 = nn.Linear(64, 2)\n",
        "        self.drop = nn.Dropout(p=0.5)  # 確率0.5でdropoutすることを宣言\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.drop(self.fc1(x)))  # Dropoutの実施\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# ネットワークをGPUに送る\n",
        "model = Net()\n",
        "model = model.to(device)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvjmHQ50mb1f",
        "colab_type": "code",
        "outputId": "2791a81e-7dbb-4e02-bd1f-f0648e1e987f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "summary(model, (1,906))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                [-1, 1, 64]          58,048\n",
            "           Dropout-2                [-1, 1, 64]               0\n",
            "            Linear-3                 [-1, 1, 2]             130\n",
            "================================================================\n",
            "Total params: 58,178\n",
            "Trainable params: 58,178\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.22\n",
            "Estimated Total Size (MB): 0.23\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkB1eBDooqR2",
        "colab_type": "text"
      },
      "source": [
        "再度、学習の実施。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7Tju8RNmgKd",
        "colab_type": "code",
        "outputId": "fc355f88-85e2-4cf0-ab1a-eef354622221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "epochs = 20\n",
        "batch_size = 32\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "outdir = \".\"\n",
        "\n",
        "# 損失関数（クロスエントロピー）、\n",
        "# パラメータの最適化方法、学習率の更新方法を定義。\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)\n",
        "\n",
        "# 実際の学習を実施\n",
        "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=epochs)\n",
        "# テストデータでの精度を求める\n",
        "print_test_accuracy(model, criterion, 'test')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=906, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=2, bias=True)\n",
            "  (drop): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "\n",
            "Epoch:0/19\ttrain Loss: 0.7624 Acc: 0.5050 Time: 0.0409\tval Loss: 0.7111 Acc: 0.5025 Time: 0.0081\n",
            "Epoch:1/19\ttrain Loss: 0.6759 Acc: 0.5721 Time: 0.0339\tval Loss: 0.6775 Acc: 0.4975 Time: 0.0061\n",
            "Epoch:2/19\ttrain Loss: 0.6474 Acc: 0.6040 Time: 0.0339\tval Loss: 0.6229 Acc: 0.7286 Time: 0.0066\n",
            "Epoch:3/19\ttrain Loss: 0.6147 Acc: 0.6829 Time: 0.0333\tval Loss: 0.6016 Acc: 0.6784 Time: 0.0065\n",
            "Epoch:4/19\ttrain Loss: 0.6010 Acc: 0.6762 Time: 0.0362\tval Loss: 0.5330 Acc: 0.9447 Time: 0.0061\n",
            "Epoch:5/19\ttrain Loss: 0.5056 Acc: 0.7768 Time: 0.0335\tval Loss: 0.4427 Acc: 0.9296 Time: 0.0063\n",
            "Epoch:6/19\ttrain Loss: 0.4434 Acc: 0.8456 Time: 0.0386\tval Loss: 0.4083 Acc: 0.8693 Time: 0.0078\n",
            "Epoch:7/19\ttrain Loss: 0.4009 Acc: 0.8456 Time: 0.0326\tval Loss: 0.3047 Acc: 0.9548 Time: 0.0062\n",
            "Epoch:8/19\ttrain Loss: 0.4320 Acc: 0.7953 Time: 0.0336\tval Loss: 0.3333 Acc: 0.9447 Time: 0.0059\n",
            "Epoch:9/19\ttrain Loss: 0.4106 Acc: 0.8523 Time: 0.0372\tval Loss: 0.3365 Acc: 0.9497 Time: 0.0077\n",
            "Epoch:10/19\ttrain Loss: 0.3885 Acc: 0.8607 Time: 0.0340\tval Loss: 0.2988 Acc: 0.9648 Time: 0.0061\n",
            "Epoch:11/19\ttrain Loss: 0.3434 Acc: 0.8826 Time: 0.0332\tval Loss: 0.4094 Acc: 0.7789 Time: 0.0059\n",
            "Epoch:12/19\ttrain Loss: 0.3593 Acc: 0.8725 Time: 0.0331\tval Loss: 0.2525 Acc: 0.9648 Time: 0.0059\n",
            "Epoch:13/19\ttrain Loss: 0.3172 Acc: 0.8859 Time: 0.0334\tval Loss: 0.2323 Acc: 0.9447 Time: 0.0061\n",
            "Epoch:14/19\ttrain Loss: 0.3070 Acc: 0.9094 Time: 0.0374\tval Loss: 0.2173 Acc: 0.9447 Time: 0.0062\n",
            "Epoch:15/19\ttrain Loss: 0.2930 Acc: 0.9010 Time: 0.0314\tval Loss: 0.2055 Acc: 0.9447 Time: 0.0059\n",
            "Epoch:16/19\ttrain Loss: 0.3046 Acc: 0.8909 Time: 0.0327\tval Loss: 0.2625 Acc: 0.8844 Time: 0.0060\n",
            "Epoch:17/19\ttrain Loss: 0.3084 Acc: 0.8876 Time: 0.0334\tval Loss: 0.2354 Acc: 0.9447 Time: 0.0061\n",
            "Epoch:18/19\ttrain Loss: 0.2967 Acc: 0.8993 Time: 0.0330\tval Loss: 0.2084 Acc: 0.9497 Time: 0.0060\n",
            "Epoch:19/19\ttrain Loss: 0.2886 Acc: 0.9094 Time: 0.0347\tval Loss: 0.1908 Acc: 0.9447 Time: 0.0090\n",
            "\n",
            "Training complete in 0m 1s\n",
            "Best val acc: 0.9648\n",
            "On Test:\tLoss: 0.3018 Acc: 0.9246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XM9gno8pGnt",
        "colab_type": "text"
      },
      "source": [
        "層の数を増やしてみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXeDkX3ImtUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(906, 32)\n",
        "        self.fc2 = nn.Linear(32, 16)\n",
        "        self.fc3 = nn.Linear(16, 8)\n",
        "        self.fc4 = nn.Linear(8, 2)\n",
        "        self.drop = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.drop(self.fc1(x)))\n",
        "        x = F.relu(self.drop(self.fc2(x)))\n",
        "        x = F.relu(self.drop(self.fc3(x)))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "model = Net()\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6gaDZgepcOe",
        "colab_type": "code",
        "outputId": "fb0e5023-fb20-46ac-b2a3-d26918a73a1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "summary(model, (1,906))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                [-1, 1, 32]          29,024\n",
            "           Dropout-2                [-1, 1, 32]               0\n",
            "            Linear-3                [-1, 1, 16]             528\n",
            "           Dropout-4                [-1, 1, 16]               0\n",
            "            Linear-5                 [-1, 1, 8]             136\n",
            "           Dropout-6                 [-1, 1, 8]               0\n",
            "            Linear-7                 [-1, 1, 2]              18\n",
            "================================================================\n",
            "Total params: 29,706\n",
            "Trainable params: 29,706\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.11\n",
            "Estimated Total Size (MB): 0.12\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_6-oAQYphIj",
        "colab_type": "code",
        "outputId": "cf5fad5b-667e-450f-b022-2054c4c65f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 50\n",
        "batch_size = 32\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "outdir = \".\"\n",
        "\n",
        "# 損失関数（クロスエントロピー）、\n",
        "# パラメータの最適化方法、学習率の更新方法を定義。\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)\n",
        "\n",
        "# 実際の学習を実施\n",
        "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=epochs)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=906, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=16, bias=True)\n",
            "  (fc3): Linear(in_features=16, out_features=8, bias=True)\n",
            "  (fc4): Linear(in_features=8, out_features=2, bias=True)\n",
            "  (drop): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "\n",
            "Epoch:0/49\ttrain Loss: 0.6908 Acc: 0.5336 Time: 0.0631\tval Loss: 0.6933 Acc: 0.4975 Time: 0.0082\n",
            "Epoch:1/49\ttrain Loss: 0.6959 Acc: 0.5352 Time: 0.0515\tval Loss: 0.6936 Acc: 0.4975 Time: 0.0080\n",
            "Epoch:2/49\ttrain Loss: 0.6955 Acc: 0.5134 Time: 0.0490\tval Loss: 0.6938 Acc: 0.4975 Time: 0.0077\n",
            "Epoch:3/49\ttrain Loss: 0.6925 Acc: 0.5235 Time: 0.0520\tval Loss: 0.6938 Acc: 0.4975 Time: 0.0078\n",
            "Epoch:4/49\ttrain Loss: 0.6944 Acc: 0.5252 Time: 0.0571\tval Loss: 0.6938 Acc: 0.4975 Time: 0.0079\n",
            "Epoch:5/49\ttrain Loss: 0.6959 Acc: 0.5050 Time: 0.0467\tval Loss: 0.6939 Acc: 0.4975 Time: 0.0075\n",
            "Epoch:6/49\ttrain Loss: 0.6950 Acc: 0.5050 Time: 0.0471\tval Loss: 0.6940 Acc: 0.4975 Time: 0.0073\n",
            "Epoch:7/49\ttrain Loss: 0.6908 Acc: 0.5302 Time: 0.0501\tval Loss: 0.6940 Acc: 0.4975 Time: 0.0071\n",
            "Epoch:8/49\ttrain Loss: 0.6880 Acc: 0.5621 Time: 0.0451\tval Loss: 0.6941 Acc: 0.4975 Time: 0.0089\n",
            "Epoch:9/49\ttrain Loss: 0.6893 Acc: 0.5252 Time: 0.0452\tval Loss: 0.6943 Acc: 0.4975 Time: 0.0079\n",
            "Epoch:10/49\ttrain Loss: 0.6936 Acc: 0.5134 Time: 0.0456\tval Loss: 0.6942 Acc: 0.4975 Time: 0.0080\n",
            "Epoch:11/49\ttrain Loss: 0.6940 Acc: 0.5134 Time: 0.0491\tval Loss: 0.6943 Acc: 0.4975 Time: 0.0076\n",
            "Epoch:12/49\ttrain Loss: 0.6919 Acc: 0.5252 Time: 0.0460\tval Loss: 0.6942 Acc: 0.4975 Time: 0.0076\n",
            "Epoch:13/49\ttrain Loss: 0.6903 Acc: 0.5352 Time: 0.0460\tval Loss: 0.6943 Acc: 0.4975 Time: 0.0079\n",
            "Epoch:14/49\ttrain Loss: 0.6896 Acc: 0.5470 Time: 0.0459\tval Loss: 0.6942 Acc: 0.4975 Time: 0.0077\n",
            "Epoch:15/49\ttrain Loss: 0.6876 Acc: 0.5403 Time: 0.0496\tval Loss: 0.6943 Acc: 0.4975 Time: 0.0077\n",
            "Epoch:16/49\ttrain Loss: 0.6908 Acc: 0.5185 Time: 0.0478\tval Loss: 0.6944 Acc: 0.4975 Time: 0.0092\n",
            "Epoch:17/49\ttrain Loss: 0.6835 Acc: 0.5705 Time: 0.0534\tval Loss: 0.6945 Acc: 0.4975 Time: 0.0072\n",
            "Epoch:18/49\ttrain Loss: 0.6897 Acc: 0.5386 Time: 0.0492\tval Loss: 0.6952 Acc: 0.4975 Time: 0.0086\n",
            "Epoch:19/49\ttrain Loss: 0.6815 Acc: 0.5822 Time: 0.0485\tval Loss: 0.6938 Acc: 0.4975 Time: 0.0072\n",
            "Epoch:20/49\ttrain Loss: 0.6831 Acc: 0.5537 Time: 0.0469\tval Loss: 0.6945 Acc: 0.4975 Time: 0.0070\n",
            "Epoch:21/49\ttrain Loss: 0.6843 Acc: 0.5604 Time: 0.0490\tval Loss: 0.6948 Acc: 0.4975 Time: 0.0079\n",
            "Epoch:22/49\ttrain Loss: 0.6870 Acc: 0.5570 Time: 0.0485\tval Loss: 0.6951 Acc: 0.4975 Time: 0.0076\n",
            "Epoch:23/49\ttrain Loss: 0.6847 Acc: 0.5638 Time: 0.0507\tval Loss: 0.6937 Acc: 0.4975 Time: 0.0076\n",
            "Epoch:24/49\ttrain Loss: 0.6846 Acc: 0.5638 Time: 0.0498\tval Loss: 0.6928 Acc: 0.4975 Time: 0.0074\n",
            "Epoch:25/49\ttrain Loss: 0.6778 Acc: 0.5705 Time: 0.0476\tval Loss: 0.6773 Acc: 0.5779 Time: 0.0085\n",
            "Epoch:26/49\ttrain Loss: 0.6796 Acc: 0.5705 Time: 0.0467\tval Loss: 0.6846 Acc: 0.5025 Time: 0.0076\n",
            "Epoch:27/49\ttrain Loss: 0.6780 Acc: 0.6007 Time: 0.0509\tval Loss: 0.6767 Acc: 0.5176 Time: 0.0072\n",
            "Epoch:28/49\ttrain Loss: 0.6686 Acc: 0.6309 Time: 0.0469\tval Loss: 0.6718 Acc: 0.5678 Time: 0.0075\n",
            "Epoch:29/49\ttrain Loss: 0.6655 Acc: 0.6393 Time: 0.0469\tval Loss: 0.6703 Acc: 0.5829 Time: 0.0076\n",
            "Epoch:30/49\ttrain Loss: 0.6646 Acc: 0.6393 Time: 0.0474\tval Loss: 0.6668 Acc: 0.6281 Time: 0.0078\n",
            "Epoch:31/49\ttrain Loss: 0.6581 Acc: 0.6460 Time: 0.0521\tval Loss: 0.6629 Acc: 0.6633 Time: 0.0083\n",
            "Epoch:32/49\ttrain Loss: 0.6638 Acc: 0.6309 Time: 0.0492\tval Loss: 0.6574 Acc: 0.7538 Time: 0.0077\n",
            "Epoch:33/49\ttrain Loss: 0.6558 Acc: 0.6527 Time: 0.0497\tval Loss: 0.6524 Acc: 0.8342 Time: 0.0077\n",
            "Epoch:34/49\ttrain Loss: 0.6597 Acc: 0.6527 Time: 0.0526\tval Loss: 0.6479 Acc: 0.8894 Time: 0.0097\n",
            "Epoch:35/49\ttrain Loss: 0.6714 Acc: 0.6158 Time: 0.0546\tval Loss: 0.6566 Acc: 0.7085 Time: 0.0076\n",
            "Epoch:36/49\ttrain Loss: 0.6556 Acc: 0.6376 Time: 0.0482\tval Loss: 0.6584 Acc: 0.6884 Time: 0.0077\n",
            "Epoch:37/49\ttrain Loss: 0.6516 Acc: 0.6443 Time: 0.0485\tval Loss: 0.6404 Acc: 0.9045 Time: 0.0076\n",
            "Epoch:38/49\ttrain Loss: 0.6534 Acc: 0.6611 Time: 0.0498\tval Loss: 0.6351 Acc: 0.9296 Time: 0.0077\n",
            "Epoch:39/49\ttrain Loss: 0.6440 Acc: 0.6846 Time: 0.0538\tval Loss: 0.6330 Acc: 0.9146 Time: 0.0075\n",
            "Epoch:40/49\ttrain Loss: 0.6416 Acc: 0.6678 Time: 0.0487\tval Loss: 0.6327 Acc: 0.8995 Time: 0.0076\n",
            "Epoch:41/49\ttrain Loss: 0.6510 Acc: 0.6527 Time: 0.0470\tval Loss: 0.6317 Acc: 0.8995 Time: 0.0075\n",
            "Epoch:42/49\ttrain Loss: 0.6342 Acc: 0.6560 Time: 0.0467\tval Loss: 0.6264 Acc: 0.9146 Time: 0.0078\n",
            "Epoch:43/49\ttrain Loss: 0.6343 Acc: 0.6846 Time: 0.0503\tval Loss: 0.6292 Acc: 0.8894 Time: 0.0072\n",
            "Epoch:44/49\ttrain Loss: 0.6361 Acc: 0.6661 Time: 0.0515\tval Loss: 0.6173 Acc: 0.9497 Time: 0.0074\n",
            "Epoch:45/49\ttrain Loss: 0.6410 Acc: 0.6644 Time: 0.0464\tval Loss: 0.6185 Acc: 0.9246 Time: 0.0074\n",
            "Epoch:46/49\ttrain Loss: 0.6411 Acc: 0.6762 Time: 0.0476\tval Loss: 0.6222 Acc: 0.8995 Time: 0.0077\n",
            "Epoch:47/49\ttrain Loss: 0.6343 Acc: 0.6762 Time: 0.0530\tval Loss: 0.6092 Acc: 0.9497 Time: 0.0077\n",
            "Epoch:48/49\ttrain Loss: 0.6238 Acc: 0.6846 Time: 0.0472\tval Loss: 0.6071 Acc: 0.9497 Time: 0.0077\n",
            "Epoch:49/49\ttrain Loss: 0.6269 Acc: 0.6913 Time: 0.0487\tval Loss: 0.6028 Acc: 0.9497 Time: 0.0082\n",
            "\n",
            "Training complete in 0m 3s\n",
            "Best val acc: 0.9497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aCDHHKN69jL",
        "colab_type": "code",
        "outputId": "010a04e1-d94e-4706-ff6d-8a30c5d6361a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# テストデータでの精度を求める\n",
        "print_test_accuracy(model, criterion, 'test')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On Test:\tLoss: 0.6153 Acc: 0.9246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OqF7c4wovNA",
        "colab_type": "text"
      },
      "source": [
        "以上で、発現量を利用した深層ではないニューラルネットワークを実施した。層の数や層内のノードの数など、様々な変更可能な点が存在しているので、色々と試してみてほしい。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkrJPS9qMCBe",
        "colab_type": "text"
      },
      "source": [
        "# 2. 学習経過の表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SumQxiiEpDfU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "475b01df-6765-4ba4-8918-8ddc9d11dc9e"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./runs"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 1546), started 1:18:53 ago. (Use '!kill 1546' to kill it.)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div id=\"root\"></div>\n",
              "    <script>\n",
              "      (function() {\n",
              "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
              "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
              "        document.querySelector(\"base\").href = \"https://localhost:6006\";\n",
              "        function fixUpTensorboard(root) {\n",
              "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
              "          // Disable the fragment manipulation behavior in Colab. Not\n",
              "          // only is the behavior not useful (as the iframe's location\n",
              "          // is not visible to the user), it causes TensorBoard's usage\n",
              "          // of `window.replace` to navigate away from the page and to\n",
              "          // the `localhost:<port>` URL specified by the base URI, which\n",
              "          // in turn causes the frame to (likely) crash.\n",
              "          tftb.removeAttribute(\"use-hash\");\n",
              "        }\n",
              "        function executeAllScripts(root) {\n",
              "          // When `script` elements are inserted into the DOM by\n",
              "          // assigning to an element's `innerHTML`, the scripts are not\n",
              "          // executed. Thus, we manually re-insert these scripts so that\n",
              "          // TensorBoard can initialize itself.\n",
              "          for (const script of root.querySelectorAll(\"script\")) {\n",
              "            const newScript = document.createElement(\"script\");\n",
              "            newScript.type = script.type;\n",
              "            newScript.textContent = script.textContent;\n",
              "            root.appendChild(newScript);\n",
              "            script.remove();\n",
              "          }\n",
              "        }\n",
              "        function setHeight(root, height) {\n",
              "          // We set the height dynamically after the TensorBoard UI has\n",
              "          // been initialized. This avoids an intermediate state in\n",
              "          // which the container plus the UI become taller than the\n",
              "          // final width and cause the Colab output frame to be\n",
              "          // permanently resized, eventually leading to an empty\n",
              "          // vertical gap below the TensorBoard UI. It's not clear\n",
              "          // exactly what causes this problematic intermediate state,\n",
              "          // but setting the height late seems to fix it.\n",
              "          root.style.height = `${height}px`;\n",
              "        }\n",
              "        const root = document.getElementById(\"root\");\n",
              "        fetch(\".\")\n",
              "          .then((x) => x.text())\n",
              "          .then((html) => void (root.innerHTML = html))\n",
              "          .then(() => fixUpTensorboard(root))\n",
              "          .then(() => executeAllScripts(root))\n",
              "          .then(() => setHeight(root, 800));\n",
              "      })();\n",
              "    </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "figYsVDjMa_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7f7b5727-5f82-4448-91e8-34f91916db95"
      },
      "source": [
        "from tensorboardcolab import TensorBoardColab\n",
        "tbc = TensorBoardColab()    "
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://224b6986.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5etnajAbJon",
        "colab_type": "text"
      },
      "source": [
        "表示されるURLをクリックして、タブを開いておいてください。\n",
        "後ほど、学習のグラフが描かれます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55casQwkN6MD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ネットワークの定義。1.1.2と同様\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(906, 64)\n",
        "        self.fc2 = nn.Linear(64, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# 学習の定義。変更点は、\n",
        "# 1. Tensorboard用の表記, 2. わざとepochごとに3秒のインターバルを入れた\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "    # 途中経過でモデル保存するための初期化\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    # 時間計測用\n",
        "    end = time.time()\n",
        "    \n",
        "    # ネットワークの表示\n",
        "    print(model)\n",
        "    print()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch:{}/{}'.format(epoch, num_epochs - 1), end=\"\")\n",
        "\n",
        "        # 各エポックで訓練+バリデーションを実行\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train(True)  # training mode\n",
        "            else:\n",
        "                model.train(False)  # evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                labels = labels.float()\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 訓練のときだけ履歴を保持する\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, classnums = torch.max(labels, 1)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, classnums)\n",
        "                    # 訓練時にはバックプロパゲーションを実施\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # 統計情報\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == classnums)\n",
        "                \n",
        "            # サンプル数で割って平均を求める\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('\\t{} Loss: {:.4f} Acc: {:.4f} Time: {:.4f}'.format(phase, epoch_loss, epoch_acc, time.time()-end), end=\"\")\n",
        "            # Tensorboard 用に追加\n",
        "            if phase == 'train':\n",
        "                tbc.save_value('Loss', 'train_loss', epoch, epoch_loss)\n",
        "                tbc.flush_line('train_loss')\n",
        "            else:\n",
        "                tbc.save_value('Loss', 'val_loss', epoch, epoch_loss)\n",
        "                tbc.flush_line('val_loss')\n",
        "                \n",
        "            \n",
        "            # 学習が進むに連れ、更新量を減らすための処理\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "            # 精度が改善したらモデルを保存する\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            end = time.time()\n",
        "            time.sleep(3) # 実行が速すぎるので、わざと休止を入れる\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print()\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val acc: {:.4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "model = Net()\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKH6_U7kSTe8",
        "colab_type": "text"
      },
      "source": [
        "学習の実施。学習中、先程のURLのページを眺めてください。30秒ごとに、学習経過が表示されます。\n",
        "頻繁にチェックしすぎると、制限を超えるので、気をつけてください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip_sy77fPvK8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "22151768-a98b-48dc-c1b8-6c6ffd5a6459"
      },
      "source": [
        "epochs = 25\n",
        "batch_size = 32\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "outdir = \".\"\n",
        "\n",
        "# 損失関数（クロスエントロピー）、\n",
        "# パラメータの最適化方法、学習率の更新方法を定義。\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)\n",
        "\n",
        "# 実際の学習を実施\n",
        "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=epochs)\n",
        "\n",
        "tbc.close()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=906, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "\n",
            "Epoch:0/24\ttrain Loss: 0.6846 Acc: 0.5554 Time: 0.0424\tval Loss: 0.6122 Acc: 0.6382 Time: 3.0099\n",
            "Epoch:1/24\ttrain Loss: 0.5308 Acc: 0.8154 Time: 3.0342\tval Loss: 0.4746 Acc: 0.9347 Time: 3.0098\n",
            "Epoch:2/24\ttrain Loss: 0.4421 Acc: 0.8440 Time: 3.0375\tval Loss: 0.3791 Acc: 0.9347 Time: 3.0102\n",
            "Epoch:3/24\ttrain Loss: 0.3311 Acc: 0.9161 Time: 3.0344\tval Loss: 0.3211 Acc: 0.8995 Time: 3.0097\n",
            "Epoch:4/24\ttrain Loss: 0.2888 Acc: 0.8993 Time: 3.0360\tval Loss: 0.4575 Acc: 0.7236 Time: 3.0098\n",
            "Epoch:5/24\ttrain Loss: 0.2828 Acc: 0.9044 Time: 3.0375\tval Loss: 0.2334 Acc: 0.9548 Time: 3.0096\n",
            "Epoch:6/24\ttrain Loss: 0.2792 Acc: 0.8809 Time: 3.0377\tval Loss: 0.2916 Acc: 0.9045 Time: 3.0099\n",
            "Epoch:7/24\ttrain Loss: 0.2022 Acc: 0.9379 Time: 3.0375\tval Loss: 0.1832 Acc: 0.9598 Time: 3.0100\n",
            "Epoch:8/24\ttrain Loss: 0.2045 Acc: 0.9329 Time: 3.0374\tval Loss: 0.2436 Acc: 0.8945 Time: 3.0099\n",
            "Epoch:9/24\ttrain Loss: 0.2231 Acc: 0.9295 Time: 3.0363\tval Loss: 0.1732 Acc: 0.9447 Time: 3.0096\n",
            "Epoch:10/24\ttrain Loss: 0.2034 Acc: 0.9312 Time: 3.0369\tval Loss: 0.2316 Acc: 0.9246 Time: 3.0098\n",
            "Epoch:11/24\ttrain Loss: 0.1798 Acc: 0.9463 Time: 3.0369\tval Loss: 0.1738 Acc: 0.9648 Time: 3.0082\n",
            "Epoch:12/24\ttrain Loss: 0.1698 Acc: 0.9446 Time: 3.0387\tval Loss: 0.1633 Acc: 0.9447 Time: 3.0093\n",
            "Epoch:13/24\ttrain Loss: 0.1751 Acc: 0.9497 Time: 3.0356\tval Loss: 0.1486 Acc: 0.9497 Time: 3.0147\n",
            "Epoch:14/24\ttrain Loss: 0.1563 Acc: 0.9497 Time: 3.0370\tval Loss: 0.1480 Acc: 0.9497 Time: 3.0093\n",
            "Epoch:15/24\ttrain Loss: 0.1593 Acc: 0.9530 Time: 3.0377\tval Loss: 0.1580 Acc: 0.9497 Time: 3.0100\n",
            "Epoch:16/24\ttrain Loss: 0.1587 Acc: 0.9480 Time: 3.0372\tval Loss: 0.1873 Acc: 0.9497 Time: 3.0102\n",
            "Epoch:17/24\ttrain Loss: 0.1682 Acc: 0.9480 Time: 3.0372\tval Loss: 0.1409 Acc: 0.9497 Time: 3.0104\n",
            "Epoch:18/24\ttrain Loss: 0.1528 Acc: 0.9463 Time: 3.0358\tval Loss: 0.1903 Acc: 0.9347 Time: 3.0097\n",
            "Epoch:19/24\ttrain Loss: 0.1734 Acc: 0.9480 Time: 3.0374\tval Loss: 0.1398 Acc: 0.9598 Time: 3.0102\n",
            "Epoch:20/24\ttrain Loss: 0.1519 Acc: 0.9497 Time: 3.0341\tval Loss: 0.1776 Acc: 0.9497 Time: 3.0093\n",
            "Epoch:21/24\ttrain Loss: 0.1544 Acc: 0.9513 Time: 3.0361\tval Loss: 0.1372 Acc: 0.9548 Time: 3.0085\n",
            "Epoch:22/24\ttrain Loss: 0.1449 Acc: 0.9581 Time: 3.0364\tval Loss: 0.1405 Acc: 0.9598 Time: 3.0077\n",
            "Epoch:23/24\ttrain Loss: 0.1466 Acc: 0.9513 Time: 3.0378\tval Loss: 0.1369 Acc: 0.9598 Time: 3.0101\n",
            "Epoch:24/24\ttrain Loss: 0.1417 Acc: 0.9513 Time: 3.0366\tval Loss: 0.1346 Acc: 0.9497 Time: 3.0100\n",
            "\n",
            "Training complete in 2m 31s\n",
            "Best val acc: 0.9648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU7uIwOWPy0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}